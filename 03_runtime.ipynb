{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EomMyr6bvyge"
      },
      "source": [
        "# Runtime and basic example demonstration\n",
        "\n",
        "In this example simple kernel program with runtime code is showcased.</br>\n",
        "This example shows how to send float32 array to the GPU and calculate in parallel $\\sin(x)$ of each element in array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4DsbqEIvsMP"
      },
      "outputs": [],
      "source": [
        "!pip install pyopencl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEzaC8QzvdLy"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0J6nlzQ4gZL"
      },
      "source": [
        "## Kernel code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile program.cl\n",
        "\n",
        "__kernel void sinus(__global float* a) {\n",
        "    int i = get_global_id(0);\n",
        "    a[i] = sin(a[i]);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbjxR6ht0uXw"
      },
      "source": [
        "- `__kernel` - qualifier that declares that a function can be executed as kernel on a OpenCL device when called by host\n",
        "- `__global` - indicates that memory object is allocated in global memory space\n",
        "- `get_global_id(0)` - returns global work-item ID based on the number of global work-items specified to execute the kernel. Argument passed to this function specifies dimension eg. dimension 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qgksps6h23tK"
      },
      "source": [
        "By convetion, file that have kernel programs inside have `.cl` extension.</br>\n",
        "In order to run this example, `.cl` program must be created and stored in local directory of VM instance.\n",
        "Command `%%writefile program.cl` will create file and write contents of cell in it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61XlI32W4ZX2"
      },
      "source": [
        "## Runtime code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q89_YDMR8xdc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "\n",
        "np.random.seed(0)       # initializing seed for random function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOpQ0N-Kb2i9"
      },
      "source": [
        "Using NumPy we will generate array that will be send to the device to be processed.</br>\n",
        "`np.random.rand()` function we will generate elements from [0,1) interval and we will convert them to float32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pykeDj2eaUjM"
      },
      "outputs": [],
      "source": [
        "size_of_array = 100\n",
        "array = np.random.randn(size_of_array).astype(np.float32)\n",
        "print(array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF5MlgiiWDfD"
      },
      "source": [
        "First we need to create a context and assign platform and device objects to that context. Available devices can be retrieved from platform object. Additionally, each program, buffer and command queue object must be assigned to some context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wIbOudaT2fF"
      },
      "outputs": [],
      "source": [
        "platform = cl.get_platforms()[0]\n",
        "gpu_device = platform.get_devices()[0]\n",
        "\n",
        "context = cl.Context(\n",
        "    devices=[gpu_device],\n",
        "    properties=[(cl.context_properties.PLATFORM, platform)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4my5YAfmWs85"
      },
      "source": [
        "Each device needs it's own command queue. Command queue is used to call kernel execution, send and retrieve data from the device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jrWGh5rU4Lx"
      },
      "outputs": [],
      "source": [
        "queue = cl.CommandQueue(context, gpu_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJvLEu9Xya7"
      },
      "source": [
        "Next we want to create a buffer object that will be a reference to data that is stored on a device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWU_z6wwV9xk"
      },
      "outputs": [],
      "source": [
        "buffer = cl.Buffer(context, cl.mem_flags.READ_WRITE, array.nbytes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgvO52SkdEOe"
      },
      "source": [
        "Now we need to load our program file that has kernel function create program object and compile our kernel. After that we set arguments of our kernel this is done by passing buffers with data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csg3JaJhdM-M"
      },
      "outputs": [],
      "source": [
        "program_file = open(\"program.cl\", \"r\")\n",
        "program_src = program_file.read()\n",
        "\n",
        "program = cl.Program(context, program_src)\n",
        "program.build()                              # here the compilation process happens\n",
        "kernel = program.sinus                       # here we link our kernel object\n",
        "\n",
        "kernel.set_args(buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri4VcFScexgz"
      },
      "source": [
        "Copying data from host memory to memory on the device and assigning buffer object to that block of memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CnLHFTUfNWm"
      },
      "outputs": [],
      "source": [
        "cl.enqueue_copy(queue, buffer, array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbAY3bAShuw-"
      },
      "source": [
        "Finally, we send kernel function to device and initiate work-items that will copy and run kernel.</br>\n",
        "We will launch same number of work-items as number of elements in array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fYtxc4Ih_R5"
      },
      "outputs": [],
      "source": [
        "global_work_size = (size_of_array,)\n",
        "local_work_size = (size_of_array,)\n",
        "cl.enqueue_nd_range_kernel(queue, kernel, global_work_size, local_work_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fekFG27tjffm"
      },
      "source": [
        "Calculation is finished, so we need to return data from device memory to host. We create empty result array and copy results there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xW2HjF2jtpa"
      },
      "outputs": [],
      "source": [
        "result_gpu = np.empty(size_of_array, dtype=np.float32)\n",
        "cl.enqueue_copy(queue, result_gpu, buffer)\n",
        "\n",
        "print(result_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEni0ARVkef5"
      },
      "source": [
        "# Let's check if results are valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn0GELtjko4a"
      },
      "source": [
        "We will do the same calculation and compare if results from cpu and gpu are approximately the same. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7ZmqCtVlH-p"
      },
      "outputs": [],
      "source": [
        "result_cpu = np.sin(array)\n",
        "\n",
        "are_same = np.allclose(result_cpu, result_gpu)\n",
        "print(\"Results from CPU and GPU are same: \", are_same)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRwhzA7dvdMF"
      },
      "source": [
        "# Some useful shortcuts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJnKgLexvdMG"
      },
      "source": [
        "OpenCL can automatically create context and assign devices from available platforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j4F84f-wY3n"
      },
      "outputs": [],
      "source": [
        "ctx = cl.create_some_context()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mDVhnAA7vdMH"
      },
      "source": [
        "When creating buffer object data can be automatically copied and assigned to that buffer object by passing memory flag `COPY_HOST_PTR` and `hostbuf`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBOSzsm_vdMH"
      },
      "outputs": [],
      "source": [
        "mf = cl.mem_flags\n",
        "array_buffer = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3hnV9qsvdMI"
      },
      "source": [
        "Setting kernel arguments and enqueueing work-items can be done throught one kernel call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DzqYaYwvdMI"
      },
      "outputs": [],
      "source": [
        "kernel(queue, global_work_size, local_work_size, buffer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "03_runtime.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
